{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull_neptune_data\n",
    "import os\n",
    "import zipfile\n",
    "from typing import List\n",
    "\n",
    "import neptune\n",
    "from colorama import Fore, Style\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "# merge_json_files\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_neptune_data(\n",
    "    project_name: str,\n",
    "    tag: List,\n",
    "    store_directory: str = \"./downloaded_json_data\",\n",
    "    neptune_data_key: str = \"metrics\",\n",
    ") -> None:\n",
    "    \"\"\"Pulls experiment json data from Neptune to a local directory.\n",
    "\n",
    "    Args:\n",
    "        project_name (str): Name of the Neptune project.\n",
    "        tag (List): List of tags for the experiment(s) that contain the\n",
    "            desired JSON files.\n",
    "        store_directory (str, optional): Directory to store the data.\n",
    "            Default: ./downloaded_json_data.\n",
    "        neptune_data_key (str, optional): Key in the neptune run where the\n",
    "            json data is stored. Default: metrics.\n",
    "    \"\"\"\n",
    "    # Get the run ids\n",
    "    project = neptune.init_project(project=project_name,\n",
    "                                   api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlNTdmNjcwMC03NmIxLTQ0MGQtYTMzMC1jYzUyNmRiNzc1ZWMifQ==')\n",
    "    runs_table_df = project.fetch_runs_table(state=\"inactive\", tag=tag).to_pandas()\n",
    "    run_ids = runs_table_df[\"sys/id\"].values.tolist()\n",
    "\n",
    "    # Check if store_directory exists\n",
    "    if not os.path.exists(store_directory):\n",
    "        os.makedirs(store_directory)\n",
    "\n",
    "    # Suppress neptune logger\n",
    "    neptune_logger = logging.getLogger('neptune')\n",
    "    neptune_logger.setLevel(logging.ERROR)\n",
    "\n",
    "    # Download and unzip the data\n",
    "    for run_id in tqdm(run_ids, desc=\"Downloading Neptune Data\"):\n",
    "        run = neptune.init_run(project=project_name, with_id=run_id, mode=\"read-only\", \n",
    "                               api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJlNTdmNjcwMC03NmIxLTQ0MGQtYTMzMC1jYzUyNmRiNzc1ZWMifQ==')\n",
    "        for j, data_key in enumerate(run.get_structure()[neptune_data_key].keys(), start=1):\n",
    "            # Create a unique filename\n",
    "            file_path = f\"{store_directory}/{data_key}_{run_id}_{j}\"\n",
    "            run[f\"{neptune_data_key}/{data_key}\"].download(destination=file_path)\n",
    "            # Try to unzip the file else continue to the next file\n",
    "            try:\n",
    "                with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n",
    "                    # Create a directory to store unzipped data\n",
    "                    os.makedirs(f\"{file_path}_unzip\", exist_ok=True)\n",
    "                    # Unzip the data\n",
    "                    zip_ref.extractall(f\"{file_path}_unzip\")\n",
    "                    # Remove the zip file\n",
    "                    os.remove(file_path)\n",
    "            except zipfile.BadZipFile:\n",
    "                # If the file is not zipped continue to the next file\n",
    "                # as it is already downloaded and doesn't need to be\n",
    "                # unzipped.\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while unzipping or storing {file_path}: {e}\")\n",
    "        run.stop()\n",
    "    \n",
    "    # Restore neptune logger level\n",
    "    neptune_logger.setLevel(logging.INFO)\n",
    "\n",
    "    print(f\"{Fore.CYAN}{Style.BRIGHT}Data downloaded successfully!{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/InstaDeep/Mava/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcdb661ce5243b8ad233d3c59bad390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching table...: 0 [00:00, ?/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Neptune Data: 100%|██████████| 480/480 [07:26<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mData downloaded successfully!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pull_neptune_data(project_name=\"InstaDeep/Mava\", tag=[\"matrax-measure-set-benchmark\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_json_files(directory: str) -> list:\n",
    "    \"\"\"Reads all JSON files in a directory and returns a list of JSON objects.\"\"\"\n",
    "    json_data = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".json\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                with open(file_path) as file:\n",
    "                    json_data.append(json.load(file))\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "def _get_seed_number(seed_str: str) -> Tuple[str, int]:\n",
    "    \"\"\"Get the seed number from the seed string.\"\"\"\n",
    "    if seed_str.isnumeric():\n",
    "        return \"\", int(seed_str)\n",
    "    else:\n",
    "        try:\n",
    "            seed_string, seed_number = seed_str.split(\"_\")\n",
    "            return seed_string, int(seed_number)\n",
    "        except ValueError:\n",
    "            raise ValueError(\n",
    "                f\"Seed number {seed_str} is not in the correct format.\\\n",
    "                It should be an integer or a string with the format 'seed_number'\"\n",
    "            )\n",
    "\n",
    "\n",
    "def _check_seed(concatenated_data: Dict, algo_data: Dict, seed_number: str) -> str:\n",
    "    \"\"\"Function to check if seed is already in concatenated_data and algo_data.\"\"\"\n",
    "    if seed_number in (concatenated_data.keys() or algo_data.keys()):\n",
    "        seed_string, seed_n = _get_seed_number(seed_number)\n",
    "        seed_number = (\n",
    "            f\"{seed_string}_{seed_n+1}\" if seed_string != \"\" else str(seed_n + 1)\n",
    "        )\n",
    "        return _check_seed(concatenated_data, algo_data, seed_number)\n",
    "    else:\n",
    "        return seed_number\n",
    "\n",
    "\n",
    "def concatenate_json_files(\n",
    "    input_directory: str, output_json_path: str = \"concatenated_json_files/\"\n",
    ") -> Dict:\n",
    "    \"\"\"Concatenate all json files in a directory and save the result in a json file.\"\"\"\n",
    "    # Read all json files in a input_directory\n",
    "    json_data = _read_json_files(input_directory)\n",
    "\n",
    "    # Create target folder\n",
    "    if not os.path.exists(output_json_path):\n",
    "        os.makedirs(output_json_path)\n",
    "\n",
    "    # Using defaultdict for automatic handling of missing keys\n",
    "    concatenated_data: Dict = defaultdict(\n",
    "        lambda: defaultdict(lambda: defaultdict(lambda: defaultdict(list)))\n",
    "    )\n",
    "    for data in json_data:\n",
    "        for env_name, envs in data.items():\n",
    "            for scenario_name, scenarios in envs.items():\n",
    "                for algo_name, algos in scenarios.items():\n",
    "                    concatenated_data[env_name][scenario_name][algo_name]\n",
    "                    for seed_number, algo_data in algos.items():\n",
    "                        # Get seed number\n",
    "                        seed_n = _check_seed(\n",
    "                            concatenated_data[env_name][scenario_name][algo_name],\n",
    "                            algo_data,\n",
    "                            seed_number,\n",
    "                        )\n",
    "                        concatenated_data[env_name][scenario_name][algo_name][\n",
    "                            seed_n\n",
    "                        ] = algo_data\n",
    "\n",
    "    # Save concatenated data in a json file\n",
    "    if output_json_path[-1] != \"/\":\n",
    "        output_json_path += \"/\"\n",
    "    with open(f\"{output_json_path}metrics.json\", \"w\") as f:\n",
    "        json.dump(concatenated_data, f, indent=4)\n",
    "\n",
    "    print(\n",
    "        f\"{Fore.CYAN}{Style.BRIGHT}Concatenated data saved in \"\n",
    "        + f\"{output_json_path}metrics.json successfully!{Style.RESET_ALL}\"\n",
    "    )\n",
    "    return concatenated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mConcatenated data saved in concatenated_json_files/metrics.json successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "concatenated_data = concatenate_json_files(\"./downloaded_json_data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
